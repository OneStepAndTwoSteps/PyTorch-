{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - 情感分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、词表映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, tokens=None):\n",
    "        self.idx_to_token = list()\n",
    "        self.token_to_idx = dict()\n",
    "\n",
    "        if tokens is not None:\n",
    "            if \"<unk>\" not in tokens:\n",
    "                tokens = tokens + [\"<unk>\"]\n",
    "            for token in tokens:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "            self.unk = self.token_to_idx['<unk>']\n",
    "#         print(tokens)\n",
    "        \n",
    "    @classmethod\n",
    "    def build(cls, text, min_freq=1, reserved_tokens=None):\n",
    "        token_freqs = defaultdict(int)\n",
    "        for sentence in text:\n",
    "            for token in sentence:\n",
    "                token_freqs[token] += 1\n",
    "        uniq_tokens = [\"<unk>\"] + (reserved_tokens if reserved_tokens else [])\n",
    "        uniq_tokens += [token for token, freq in token_freqs.items() \\\n",
    "                        if freq >= min_freq and token != \"<unk>\"]\n",
    "        \n",
    "        return cls(uniq_tokens)   ## 返回cls 对象，到时候就可以通过这个cls 来调用 Vocab 类中的其他方法\n",
    "                                  ## 后面调用 build ，并且将返回值设为 vocab = cls(uniq_tokens) ，之后调用vocab，会默认带有uniq_tokens参数\n",
    "                                 ## 此 uniq_tokens 参数会传给 __init__ 中的 tokens。\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        print('調用了我')\n",
    "        print(token)\n",
    "        return self.token_to_idx.get(token, self.unk)\n",
    "    \n",
    "    ## convert_tokens_to_ids 在 self[token] 的时候会调用 __getitem__，然后 __getitem__ 返回的内容会赋值给self[token]\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        print(tokens)\n",
    "        print('开始调用')\n",
    "        return [self[token] for token in tokens] \n",
    "\n",
    "    def convert_ids_to_tokens(self, indices):\n",
    "        return [self.idx_to_token[index] for index in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、词向量层：embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(8,3) ## 词表大小为8，Embadding 向量维度为3\n",
    "\n",
    "input = torch.tensor([[0,1,2,1],[4,6,6,7]],dtype=torch.long)\n",
    "print(input.shape)\n",
    "output = embedding(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、融入词向量层的多层感知机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9529, -0.4871],\n",
      "        [-0.8838, -0.5331]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class):\n",
    "        super(MLP, self).__init__()\n",
    "        # 词嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # 线性变换：词嵌入层->隐含层\n",
    "        self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        # 使用ReLU激活函数\n",
    "        self.activate = F.relu\n",
    "        # 线性变换：激活层->输出层\n",
    "        self.linear2 = nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        # 将序列中多个embedding进行聚合（此处是求平均值）\n",
    "        embedding = embeddings.mean(dim=1)\n",
    "        hidden = self.activate(self.linear1(embedding))\n",
    "        outputs = self.linear2(hidden)\n",
    "        # 获得每个序列属于某一类别概率的对数值\n",
    "        probs = F.log_softmax(outputs, dim=1)\n",
    "        return probs\n",
    "\n",
    "mlp = MLP(vocab_size=8, embedding_dim=3, hidden_dim=5, num_class=2)\n",
    "# 输入为两个长度为4的整数序列\n",
    "inputs = torch.tensor([[0, 1, 2, 1], [4, 6, 6, 7]], dtype=torch.long)\n",
    "outputs = mlp(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (embedding): Embedding(8, 3)\n",
       "  (linear1): Linear(in_features=3, out_features=5, bias=True)\n",
       "  (linear2): Linear(in_features=5, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、数据处理：\n",
    "\n",
    "数据处理第一步为加载数据，此时读入的数据是原始数据，还需要进行分句、标记解析等预处理过程转化为标记序列，然后再使用词表映射工具将每个标记映射到相应的索引值。\n",
    "\n",
    "再此使用 NLTK 提供的句子倾向性分析数据，作为示例：\n",
    "\n",
    "#### 4.1、sentence_polarity提供了基本的数据访问方法：\n",
    "\n",
    "`sentence_polarity.categories()` 返回褒贬类别列表，即['neg','pos']；\n",
    "\n",
    "`sentence_polarity.words()` 返回语料库中全部单词的列表，如果调用时提供类别参数categories=\"pos\" or \"neg\"，则会返回相应类别的全部单词列表；\n",
    "\n",
    "`sentence_polarity.sents()` 返回语料库中全部句子的列表，调用时同样可以提供类别参数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from nltk.corpus import sentence_polarity\n",
    "\n",
    "def load_sentence_polarity():\n",
    "\n",
    "    vocab = Vocab.build(sentence_polarity.sents())\n",
    "    train_data = [(vocab.convert_tokens_to_ids(sentence), 0)\n",
    "                  for sentence in sentence_polarity.sents(categories='pos')[:2]] \\\n",
    "        + [(vocab.convert_tokens_to_ids(sentence), 1)\n",
    "            for sentence in sentence_polarity.sents(categories='neg')[:2]]\n",
    "\n",
    "#     test_data = [(vocab.convert_tokens_to_ids(sentence), 0)\n",
    "#                  for sentence in sentence_polarity.sents(categories='pos')[4000:]] \\\n",
    "#         + [(vocab.convert_tokens_to_ids(sentence), 1)\n",
    "#             for sentence in sentence_polarity.sents(categories='neg')[4000:]]\n",
    "\n",
    "    return train_data, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'rock',\n",
       " 'is',\n",
       " 'destined',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " '21st',\n",
       " \"century's\",\n",
       " 'new',\n",
       " '\"',\n",
       " 'conan',\n",
       " '\"',\n",
       " 'and',\n",
       " 'that',\n",
       " \"he's\",\n",
       " 'going',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'splash',\n",
       " 'even',\n",
       " 'greater',\n",
       " 'than',\n",
       " 'arnold',\n",
       " 'schwarzenegger',\n",
       " ',',\n",
       " 'jean-claud',\n",
       " 'van',\n",
       " 'damme',\n",
       " 'or',\n",
       " 'steven',\n",
       " 'segal',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_polarity.sents(categories='pos')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', \"century's\", 'new', '\"', 'conan', '\"', 'and', 'that', \"he's\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean-claud', 'van', 'damme', 'or', 'steven', 'segal', '.']\n",
      "开始调用\n",
      "調用了我\n",
      "the\n",
      "調用了我\n",
      "rock\n",
      "調用了我\n",
      "is\n",
      "調用了我\n",
      "destined\n",
      "調用了我\n",
      "to\n",
      "調用了我\n",
      "be\n",
      "調用了我\n",
      "the\n",
      "調用了我\n",
      "21st\n",
      "調用了我\n",
      "century's\n",
      "調用了我\n",
      "new\n",
      "調用了我\n",
      "\"\n",
      "調用了我\n",
      "conan\n",
      "調用了我\n",
      "\"\n",
      "調用了我\n",
      "and\n",
      "調用了我\n",
      "that\n",
      "調用了我\n",
      "he's\n",
      "調用了我\n",
      "going\n",
      "調用了我\n",
      "to\n",
      "調用了我\n",
      "make\n",
      "調用了我\n",
      "a\n",
      "調用了我\n",
      "splash\n",
      "調用了我\n",
      "even\n",
      "調用了我\n",
      "greater\n",
      "調用了我\n",
      "than\n",
      "調用了我\n",
      "arnold\n",
      "調用了我\n",
      "schwarzenegger\n",
      "調用了我\n",
      ",\n",
      "調用了我\n",
      "jean-claud\n",
      "調用了我\n",
      "van\n",
      "調用了我\n",
      "damme\n",
      "調用了我\n",
      "or\n",
      "調用了我\n",
      "steven\n",
      "調用了我\n",
      "segal\n",
      "調用了我\n",
      ".\n",
      "[23, 2444, 61, 9851, 76, 308, 23, 1664, 14509, 496, 219, 14510, 219, 4, 27, 175, 363, 76, 29, 32, 5884, 201, 7984, 73, 5354, 4219, 2, 14511, 1204, 2701, 25, 2184, 14512, 6]\n",
      "['the', 'gorgeously', 'elaborate', 'continuation', 'of', '\"', 'the', 'lord', 'of', 'the', 'rings', '\"', 'trilogy', 'is', 'so', 'huge', 'that', 'a', 'column', 'of', 'words', 'cannot', 'adequately', 'describe', 'co-writer/director', 'peter', \"jackson's\", 'expanded', 'vision', 'of', 'j', '.', 'r', '.', 'r', '.', \"tolkien's\", 'middle-earth', '.']\n",
      "开始调用\n",
      "調用了我\n",
      "the\n",
      "調用了我\n",
      "gorgeously\n",
      "調用了我\n",
      "elaborate\n",
      "調用了我\n",
      "continuation\n",
      "調用了我\n",
      "of\n",
      "調用了我\n",
      "\"\n",
      "調用了我\n",
      "the\n",
      "調用了我\n",
      "lord\n",
      "調用了我\n",
      "of\n",
      "調用了我\n",
      "the\n",
      "調用了我\n",
      "rings\n",
      "調用了我\n",
      "\"\n",
      "調用了我\n",
      "trilogy\n",
      "調用了我\n",
      "is\n",
      "調用了我\n",
      "so\n",
      "調用了我\n",
      "huge\n",
      "調用了我\n",
      "that\n",
      "調用了我\n",
      "a\n",
      "調用了我\n",
      "column\n",
      "調用了我\n",
      "of\n",
      "調用了我\n",
      "words\n",
      "調用了我\n",
      "cannot\n",
      "調用了我\n",
      "adequately\n",
      "調用了我\n",
      "describe\n",
      "調用了我\n",
      "co-writer/director\n",
      "調用了我\n",
      "peter\n",
      "調用了我\n",
      "jackson's\n",
      "調用了我\n",
      "expanded\n",
      "調用了我\n",
      "vision\n",
      "調用了我\n",
      "of\n",
      "調用了我\n",
      "j\n",
      "調用了我\n",
      ".\n",
      "調用了我\n",
      "r\n",
      "調用了我\n",
      ".\n",
      "調用了我\n",
      "r\n",
      "調用了我\n",
      ".\n",
      "調用了我\n",
      "tolkien's\n",
      "調用了我\n",
      "middle-earth\n",
      "調用了我\n",
      ".\n",
      "[23, 4733, 5842, 14513, 22, 219, 23, 10446, 22, 23, 124, 219, 7728, 61, 8, 915, 27, 32, 4812, 22, 2012, 3524, 11773, 1451, 11941, 2200, 11627, 3281, 7293, 22, 1097, 6, 2341, 6, 2341, 6, 14514, 14515, 6]\n",
      "['simplistic', ',', 'silly', 'and', 'tedious', '.']\n",
      "开始调用\n",
      "調用了我\n",
      "simplistic\n",
      "調用了我\n",
      ",\n",
      "調用了我\n",
      "silly\n",
      "調用了我\n",
      "and\n",
      "調用了我\n",
      "tedious\n",
      "調用了我\n",
      ".\n",
      "[1, 2, 3, 4, 5, 6]\n",
      "[\"it's\", 'so', 'laddish', 'and', 'juvenile', ',', 'only', 'teenage', 'boys', 'could', 'possibly', 'find', 'it', 'funny', '.']\n",
      "开始调用\n",
      "調用了我\n",
      "it's\n",
      "調用了我\n",
      "so\n",
      "調用了我\n",
      "laddish\n",
      "調用了我\n",
      "and\n",
      "調用了我\n",
      "juvenile\n",
      "調用了我\n",
      ",\n",
      "調用了我\n",
      "only\n",
      "調用了我\n",
      "teenage\n",
      "調用了我\n",
      "boys\n",
      "調用了我\n",
      "could\n",
      "調用了我\n",
      "possibly\n",
      "調用了我\n",
      "find\n",
      "調用了我\n",
      "it\n",
      "調用了我\n",
      "funny\n",
      "調用了我\n",
      ".\n",
      "[7, 8, 9, 4, 10, 2, 11, 12, 13, 14, 15, 16, 17, 18, 6]\n"
     ]
    }
   ],
   "source": [
    "train_data,vocab = load_sentence_polarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab.idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab.token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 不过以上数据不适合给 PyTorch 直接用，可以通过 PyTorch 提供的 DataLoader 类读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_loader = DataLoader(\\n                dataset,                  ## \\n                batch_size=64,            ## 加载批大小\\n                collate_fn=collate_fn     ## \\n                shuffle=True              ## 是否随机采样\\n)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "'''\n",
    "data_loader = DataLoader(\n",
    "                dataset,                  ## \n",
    "                batch_size=64,            ## 加载批大小\n",
    "                collate_fn=collate_fn     ## \n",
    "                shuffle=True              ## 是否随机采样\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP 情感分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BowDataset(Dataset):\n",
    "    ## data 为原始数据，如使用 load_sentence_polarity 读取的训练数据和测试数据\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        # 返回数据集中样例的数目\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        # 返回下标为i的样例\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collate_fn 参数指向一个函数，用于对一个批次的样本进行整理，如将其换为张量，具体代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "    targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "    \n",
    "    offsets = [0] + [i.shape[0] for i in inputs]\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    inputs = torch.cat(inputs)\n",
    "    return inputs, offsets, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class):\n",
    "        super(MLP, self).__init__()\n",
    "        ## 词向量层\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embedding_dim)\n",
    "        ## 线性变换：词向量层 --> 隐藏层\n",
    "        self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        ## 激活函数\n",
    "        self.activate = F.relu\n",
    "        ## 线性变换：激活层 --> 输出层\n",
    "        self.linear2 = nn.Linear(hidden_dim, num_class)\n",
    "        \n",
    "    def forward(self, inputs, offsets):\n",
    "        embedding = self.embedding(inputs, offsets)\n",
    "        hidden = self.activate(self.linear1(embedding))\n",
    "        outputs = self.linear2(hidden)\n",
    "        log_probs = F.log_softmax(outputs, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm是一个Python模块，能以进度条的方式显示迭代的进度\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 超参数设置\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_class = 2\n",
    "batch_size = 32\n",
    "num_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "train_data, test_data, vocab = load_sentence_polarity()\n",
    "train_dataset = BowDataset(train_data)\n",
    "test_dataset = BowDataset(test_data)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (embedding): EmbeddingBag(21402, 128, mode=mean)\n",
       "  (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MLP(len(vocab), embedding_dim, hidden_dim, num_class)\n",
    "model.to(device) # 将模型加载到CPU或GPU设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d03147292f4417aff0e68f5d1ac0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Epoch 0', max=250, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 165.52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ed9a7af36e48da944e6765ce0a1637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Epoch 1', max=250, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 137.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a26b5e76714237b33855d9dc8c2a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Epoch 2', max=250, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 103.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a134bf863b9a4a5b9a35d35b1446fcc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Epoch 3', max=250, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 71.66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1331753ca76e45f293c41b4d54272956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Epoch 4', max=250, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 47.36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2006a75329c4474bb86a6145250ab113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Testing', max=2662, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acc: 0.72\n"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # 使用Adam优化器\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_data_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        inputs, offsets, targets = [x.to(device) for x in batch]\n",
    "        log_probs = model(inputs, offsets)\n",
    "        loss = nll_loss(log_probs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss:.2f}\")\n",
    "\n",
    "# 测试过程\n",
    "acc = 0\n",
    "for batch in tqdm(test_data_loader, desc=f\"Testing\"):\n",
    "    inputs, offsets, targets = [x.to(device) for x in batch]\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs, offsets)\n",
    "        acc += (output.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "# 输出在测试集上的准确率\n",
    "print(f\"Acc: {acc / len(test_data_loader):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 情感分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    lengths = torch.tensor([len(ex[0]) for ex in examples])\n",
    "    inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "    targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "    # 对batch内的样本进行padding，使其具有相同长度\n",
    "    inputs = pad_sequence(inputs, batch_first=True)\n",
    "    return inputs, lengths, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.output = nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "    def forward(self, inputs, lengths):\n",
    "        embeddings = self.embeddings(inputs)\n",
    "        x_pack = pack_padded_sequence(embeddings, lengths, batch_first=True, enforce_sorted=False)\n",
    "        hidden, (hn, cn) = self.lstm(x_pack)\n",
    "        outputs = self.output(hn[-1])\n",
    "        log_probs = F.log_softmax(outputs, dim=-1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_class = 2\n",
    "batch_size = 32\n",
    "num_epoch = 5\n",
    "\n",
    "#加载数据\n",
    "train_data, test_data, vocab = load_sentence_polarity()\n",
    "train_dataset = LstmDataset(train_data)\n",
    "test_dataset = LstmDataset(test_data)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embeddings): Embedding(21402, 128)\n",
       "  (lstm): LSTM(128, 256, batch_first=True)\n",
       "  (output): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#加载模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTM(len(vocab), embedding_dim, hidden_dim, num_class)\n",
    "model.to(device) #将模型加载到GPU中（如果已经正确安装）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a48d0c927134011846b688f3fea8c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Epoch 0', max=250, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 167.16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c4af555f53475d87381730e0d0105c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Epoch 1', max=250, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 139.24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7c0ffffac649d3a5e70ec659b55475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Epoch 2', max=250, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 100.18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2373a7eb2c5849c1a76070679b29e509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Epoch 3', max=250, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 62.00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38976d4fe444390b1570cf844837a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training Epoch 4', max=250, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 28.26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dacba95d64a450ba4f0974d9f9facfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Testing', max=2662, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acc: 0.71\n"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "## 在使用nllloss时，需要有两个张量，一个是预测向量，一个是label\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #使用Adam优化器\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_data_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        inputs, lengths, targets = [x.to(device) for x in batch]\n",
    "        log_probs = model(inputs, lengths)\n",
    "        loss = nll_loss(log_probs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss:.2f}\")\n",
    "\n",
    "#测试过程\n",
    "acc = 0\n",
    "for batch in tqdm(test_data_loader, desc=f\"Testing\"):\n",
    "    inputs, lengths, targets = [x.to(device) for x in batch]\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs, lengths)\n",
    "        acc += (output.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "#输出在测试集上的准确率\n",
    "print(f\"Acc: {acc / len(test_data_loader):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
